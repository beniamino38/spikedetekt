{"name":"Spikedetekt","tagline":"","body":"SpikeDetekt\r\n-----------\r\n\r\nThis is a program for spike detection. It is in development.\r\n\r\nContact: Kenneth Harris (firstname at cortexlab.net), Shabnam Kadir (firstname at cortexlab.net)\r\n\r\nQuick Start Guide for electrophysiologists (will become more comprehensive with time):\r\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\n0) Installation\r\n----------------\r\n\r\nWe recommend you use Python 2.6 or 2.7, e.g. a free academic version can be obtained from [Enthought Python](http://enthought.com/products/epd.php).\r\n\r\n\r\n\r\nOnce you have set up Python on your system, go to the SpikeDetekt folder and type (on the command line):\r\n\r\n    python setup.py install\r\n\r\nThis will install SpikeDetekt.\r\n\r\n1) Probefiles:\r\n---------------\r\n\r\nBelow are the instructions for a multi-shank probe (I hope this is clear from my example probe - otherwise do ask):\r\n\r\nConstruct a probe object from a .probe file with:\r\n\r\n   probe = Probe(filename)\r\n\r\nThe file should have a form something like:\r\n\r\n    probes = {\r\n        1: [\r\n            (0, 1), (0, 2),\r\n            (1, 2), (1, 3),\r\n            ...\r\n            ],\r\n        2: [...],\r\n        ...\r\n        }\r\n\r\nThe file is a Python file which should define a dictionary variable probes,\r\nwith keys the shank number, and values a list of channel pairs defining the\r\nedges of the graph.\r\n\r\nThe Probe object has the following attributes:\r\n\r\n* num_channels  \r\nThe number of channels used (1+the maximum channel number referred to)\r\n\r\n* channel_graph \r\n A dictionary with keys the shank number, and values being graphs. A graph being a dictionary with keys the nodes (channel number) and values the set of all connected nodes. (So each channel in an edge is referred to twice in this data structure.)\r\n\r\n* shanks_set\r\n       The set of shank numbers\r\n   \r\n* channel_set\r\n       A dictionary with keys the shank numbers, and values the \r\nset of channels for that shank\r\n\r\n* channel_to_shank\r\n       A dictionary with keys the channel numbers and values the corresponding shank number.\r\n\r\n* probes\r\n       The raw probes dictionary definition in the file.\r\n\r\n\r\n\r\nI have included some examples of probe files:\r\n\r\n* buzsaki32.probe\r\n* linear16.probe\r\n* multishankslinear32.probe (an 8 shank example)\r\n\r\n\r\n2) Parameters to adjust\r\n----------------------------\r\nCreate a file called filename.params where filename is the name of your desired output folder. It should \r\nhave the same form as the defaultparameters.py file in /spikedetekt/spikedetket/. It should contain the \r\nfollowing minimal information:\r\n\r\n    DTYPE = \"i2\" # \">i2\" (> means big-endian), \"i4\", \"f2\"\r\n    # see http://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html#arrays-dtypes-constructing\r\n\r\n    # Probe file (no default value provided)\r\n    PROBE_FILE = 'probe_filename.probe'\r\n\r\n    # Raw data files (no default values provided)\r\n    RAW_DATA_FILES = ['file1.dat', 'file2.dat','file3.dat']\r\n    NCHANNELS = 32\r\n    SAMPLERATE = 20000 # in Hertz\r\n\r\nYou can specify an ordered list of .dat files to be concatenated, in the above example file1.dat, file2.dat and file3.dat are three\r\nrecordings to be concatenated. The output files will be written to a folder\r\ncalled `filename', where outputfoldernameparams.py is the name of your parameters file. \r\n\r\nThe default parameters are as follows (see /spikedetekt/defaultparameters.py and change as desired):\r\n\r\n    DTYPE = \"i2\" # \">i2\" (> means big-endian), \"i4\", \"f2\"\r\n    # see http://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html#arrays-dtypes-constructing\r\n\r\n    # Probe file (no default value provided)\r\n    #PROBE_FILE = 'probe_filename.probe'\r\n\r\n    # Raw data files (no default values provided)\r\n    #RAW_DATA_FILES = ['file1.dat', 'file2.dat']\r\n    #NCHANNELS = 32\r\n    #SAMPLERATE = 20000 # in Hertz\r\n\r\n    # Output directory, files are inserted in OUTPUT_DIR/OUTPUT_NAME\r\n    OUTPUT_DIR = None # the output directory, use params directory if None\r\n    OUTPUT_NAME = None # the filename for created directories, use params filename if None\r\n\r\n    # Thresholding\r\n    USE_SINGLE_THRESHOLD = False # use a single threshold for all channels\r\n    CHUNKS_FOR_THRESH = 5 # number of chunks used to determine threshold for detection\r\n    THRESH_SD = 4.5 # threshold for detection. standard deviations of signal\r\n    DETECT_POSITIVE = False # detect spikes with positive threshold crossing\r\n\r\n    # Recording data in HDF5 file\r\n    RECORD_RAW = True      # raw data\r\n    RECORD_HIGH = True     # high pass filtered data\r\n    RECORD_LOW = True      # low pass filtered data\r\n\r\n    # Options for filtering\r\n    F_LOW = 500. # low pass frequency (Hz)\r\n    F_HIGH_FACTOR = 0.95 # high pass frequency as a proportion of the Nyquist freq, used to derive F_HIGH, i.e. F_HIGH = 0.95*SAMPLERATE/2 here\r\n    BUTTER_ORDER = 3 # Order of butterworth filter\r\n    WRITE_FIL_FILE = True # write filtered output to .fil file\r\n\r\n    # Options for spike detection\r\n    T_BEFORE = .0005 # time before peak in extracted spike\r\n    T_AFTER = .0005 # time after peak in extracted spike\r\n    T_JOIN_CC = .0005 # maximum time between two samples for them to be \"contiguous\" in detection step\r\n    PENUMBRA_SIZE = 0 # mask penumbra size (0 no penumbra, 1 first neighbours, etc.)\r\n\r\n    # Options for alignment\r\n    USE_WEIGHTED_MEAN_PEAK_SAMPLE = True # used for aligning waves\r\n    UPSAMPLING_FACTOR = 10 # used for aligning waves\r\n\r\n    # Options for features\r\n    FPC = 3 # Features per channel\r\n    PCA_MAXWAVES = 10000 # number of waves to use to extract principal components\r\n    SHOW_PCS = False # show principal components\r\n\r\n    # Options for masking\r\n    USE_FLOAT_MASKS = True\r\n    USE_INTERPOLATION = True\r\n    ADDITIONAL_FLOAT_PENUMBRA = 2 # adds some more penumbra\r\n    FLOAT_MASK_THRESH_SD = (0, 4.5) # (min, max), mask 0 at min, 1 at max\r\n    FLOAT_MASK_INTERPOLATION = 'x' # f(x) for x in [0,1], f(0)=0, f(1)=1\r\n\r\n    # Options for computing in chunks\r\n    CHUNK_SIZE = 20000   # number of time samples used in chunk for filtering and detection\r\n    CHUNK_OVERLAP_SECONDS = 0.01 # overlap time (in seconds) of chunks, should be wider than spike width\r\n\r\n    # Maximum number of spikes to process\r\n    MAX_SPIKES = None # None for all spikes, or an int\r\n\r\n    # Experimental options\r\n    DO_GLOBAL_CLUSTERING = False\r\n    SORT_CLUS_BY_CHANNEL = False # Sort clusters by the channel where the peak occurs\r\n    \r\n    \r\nIf you need parameters which differ from the default, include these in your outputfoldernameparams.py files. \r\n\r\n\r\n3) Running\r\n----------------------------\r\n\r\nFinally to run the program type:\r\n\r\n    python SpiKeDeteKt/scripts/detektspikes.py outputfoldernameparams.py\r\n\r\n\r\n\r\n4) Output\r\n---------------\r\n\r\nSpiKeDeteKt will output the following files, where n is your shank number:\r\n\r\n+ .fet.n (feature file - required for all versions of KlustaKwik)\r\n\r\n+ .fmask.n (float masks for using with the new masked KlustaKwik)\r\n\r\n+ .mask.n (soon to be obsolete: binary masks for using with the new (masked) KlustaKwik)\r\n\r\n+ .spk.n (spike file)\r\n\r\n+ .upsk.n (unfiltered spike waveform)\r\n\r\n+ .res.n (list of spike times)\r\n\r\n+ .clu.n (a trivial clu file for use with Neuroscope, for observing spikes after detection, before clustering. Will be made redundant later)\r\n\r\n+ .xml (an xml file with all the parameters that can subsequently be used by Neuroscope or Klusters)\r\n\r\n+ .fil (highpass filtered data)\r\n\r\n+ .h5 files (an [.h5](http://en.wikipedia.org/wiki/Hierarchical_Data_Format) file duplicating a lot of the above data, which will later replace the above).\r\n  .high.h5,\r\n  .low.h5,\r\n  .waves.h5,\r\n  .main.h5,\r\n  .raw.h5. (See spikdetekt/docs/fileformat.md for more details).\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}